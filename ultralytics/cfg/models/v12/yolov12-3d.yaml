# YOLOv12-3D ðŸš€, AGPL-3.0 license
# YOLOv12 3D object detection model for KITTI dataset with P3-P5 outputs
# Based on YOLOv12 architecture with Detect3D head for 3D bounding box prediction

# Parameters
nc: 8 # number of classes (KITTI: Car, Van, Truck, Pedestrian, Person_sitting, Cyclist, Tram, Misc)
scales: # model compound scaling constants
  # [depth, width, max_channels]
  n: [0.50, 0.25, 1024] # YOLOv12n-3D: lightweight for faster inference
  s: [0.50, 0.50, 1024] # YOLOv12s-3D: balanced speed and accuracy
  m: [0.50, 1.00, 512]  # YOLOv12m-3D: medium model
  l: [1.00, 1.00, 512]  # YOLOv12l-3D: large model for best accuracy
  x: [1.00, 1.50, 512]  # YOLOv12x-3D: extra large model

# YOLO12-3D backbone (same as YOLOv12)
backbone:
  # [from, repeats, module, args]
  - [-1, 1, Conv,  [64, 3, 2]] # 0-P1/2
  - [-1, 1, Conv,  [128, 3, 2, 1, 2]] # 1-P2/4
  - [-1, 2, C3k2,  [256, False, 0.25]]
  - [-1, 1, Conv,  [256, 3, 2, 1, 4]] # 3-P3/8
  - [-1, 2, C3k2,  [512, False, 0.25]]
  - [-1, 1, Conv,  [512, 3, 2]] # 5-P4/16
  - [-1, 4, A2C2f, [512, True, 4]]
  - [-1, 1, Conv,  [1024, 3, 2]] # 7-P5/32
  - [-1, 4, A2C2f, [1024, True, 1]] # 8

# YOLO12-3D head (with Detect3D for 3D predictions)
head:
  - [-1, 1, nn.Upsample, [None, 2, "nearest"]]
  - [[-1, 6], 1, Concat, [1]] # cat backbone P4
  - [-1, 2, A2C2f, [512, False, -1]] # 11

  - [-1, 1, nn.Upsample, [None, 2, "nearest"]]
  - [[-1, 4], 1, Concat, [1]] # cat backbone P3
  - [-1, 2, A2C2f, [256, False, -1]] # 14

  - [-1, 1, Conv, [256, 3, 2]]
  - [[-1, 11], 1, Concat, [1]] # cat head P4
  - [-1, 2, A2C2f, [512, False, -1]] # 17

  - [-1, 1, Conv, [512, 3, 2]]
  - [[-1, 8], 1, Concat, [1]] # cat head P5
  - [-1, 2, C3k2, [1024, True]] # 20 (P5/32-large)

  - [[14, 17, 20], 1, Detect3D, [nc]] # Detect3D(P3, P4, P5) - 3D detection head
